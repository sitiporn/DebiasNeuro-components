{ 
# Mitigating Spurious Correlation in Natural Language Understanding with Counterfactual Inference
# Main Model We apply the debiasing methods on the BERT base model (uncased) (Devlin et al., 2019). 
# ideas from : https://github.com/c4n/debias_nlu/blob/9d3f55449a15fe6e4538ed5713530207d2127afd/configs/nli/baseline/mnli_bert_base_clark_1.jsonnet#L4
# ************* experiment *******************
  "collect_representation": False,
  "DEBUG": True,
  "debug": False, 
  "num_samples": 300,
  "upper_bound": 95,
  "lower_bound": 5,
  "candidated_class": ["entailment"], 
  "intervention_class": ["entailment"], 
  "dataset_name":  'mnli',
  "random_adv": True,
  "collect_adv": False, 
  # eg. "random" or  "sorted"
  "top_neuron_mode": "sorted",
  "correct_pred": True,
  "label_maps": {"entailment": 0, "contradiction": 1, "neutral": 2}, # ours
  "layers": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
  "heads": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],
  "collect_param": False,
  # ******************** PATH ********************
  "model_name": "../bert-base-uncased-mnli/",
  "dev_path": "../debias_fork_clean/debias_nlu_clean/data/nli/",
  "exp_json": "multinli_1.0_dev_matched.jsonl",
  "dev_json": {},
  # data settings
  "counterfactual_paths": [],
  "NIE_paths": [],
  "is_NIE_exist": [],
  "is_counterfactual_exist": [],
  # ************ Identifying Bias: Causal Mediation Analysis *************
  # experiment set 
  "k":  5, 
  # "k":  1, 
  # rank based on nie scores 
  "eval_candidates": True,
  "layer": 11,
  "treatment": True,
  "is_group_by_class": False,
  "is_averaged_embeddings": True,
  "intervention_type": "replace",
  "computed_all_layers": True,
  "compare_frozen_weight": True, 
  "print_config": False,
  "criterion": 'topk',
  "seeds": [1548, 3099, 3785, 3990, 409], 
  # [*1548, 3099, *3785, 3990, 409] for experiments
  # "seed": 3099, #409, # set to null when using ishan/bert-base-uncased-mnli
  # Yay
  "seed": 409, # set to null when using ishan/bert-base-uncased-mnli
  # default
  # "topk_neurons": True,
  # together with compute all seeds
  "get_candidate_neurons": True,
  "distribution": False,
  # To get counterfactual
  "compute_all_seeds": True,
  "eval_counterfactual": False,
  "getting_counterfactual": False,
  "compute_nie_scores": False,
  # ******************** Unlearn Bias ********************
  "training_json":  multinli_1.0_train.jsonl, 
  "partition_params": False,
# ************ train model  *******************
  "dataset_reader": {
    "type": "snli",
    "tokenizer": {
      "type": "pretrained_transformer",
      "model_name": "../bert-base-uncased-mnli/",
      "add_special_tokens": false
    }
  },
    
  # Tokenizer
  "tokens": {
    "type": "pretrained_transformer",
    "model_name": "../bert-base-uncased-mnli/", 
    "max_length": 512
  },
  
  # dataset
  "data_path": "../debias_fork_clean/debias_nlu_clean/data/nli/",
  "train_data": "mnli_clark.train.jsonl",
  "validation_data": "multinli_1.0_dev_matched.jsonl", 
  "test_data": "multinli_1.0_dev_mismatched.jsonl",
  
  # models; 
  # follow allennlp setups, the rest is the default of bert-base-uncased
  # ************ Identifying Bias: Causal Mediation Analysis *************
  "model": {
    "model_name": "../bert-base-uncased-mnli/",
    transformer_model,
    "max_length": 512,
    "is_load_trained_model": True
  },
  
}
