{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d145a136",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from debias.datasets.mnli import load_hans, load_mnli, tokenize_examples\n",
    "import py_utils\n",
    "from load_word_vectors import load_word_vectors\n",
    "from tokenizer import NltkAndPunctTokenizer\n",
    "# import tensorflow as tf\n",
    "tok = NltkAndPunctTokenizer()\n",
    "STOP_WORDS = frozenset([\n",
    "  'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your',\n",
    "  'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her',\n",
    "  'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "  'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was',\n",
    "  'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing',\n",
    "  'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by',\n",
    "  'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above',\n",
    "  'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\n",
    "  'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few',\n",
    "  'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than',\n",
    "  'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're',\n",
    "  've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma',\n",
    "  'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn',\n",
    "   \"many\", \"how\", \"de\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "# label_maps = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "label_maps = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2}\n",
    "reverse_label_maps = {0:\"entailment\", 1:\"contradiction\", 2:\"neutral\"}\n",
    "dataset = {}\n",
    "# One: load data\n",
    "dataset['train'] = pd.read_json('../../data/nli/multinli_1.0_train.jsonl', lines=True)\n",
    "dataset['validation'] = pd.read_json('../../data/nli/multinli_1.0_dev_matched.jsonl', lines=True)\n",
    "dataset['test'] = pd.read_json('../../data/nli/multinli_1.0_dev_mismatched.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_features = {}\n",
    "for key in dataset.keys():\n",
    "    dataset[key]['gold_label'] = dataset[key]['gold_label'].map(label_maps)\n",
    "    dataset[key]['sentence1']=dataset[key]['sentence1'].apply(tok.tokenize)\n",
    "    dataset[key]['sentence2']=dataset[key]['sentence2'].apply(tok.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b32eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>genre</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>promptID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[neutral, entailment, neutral, neutral, neutral]</td>\n",
       "      <td>slate</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63735n</td>\n",
       "      <td>63735</td>\n",
       "      <td>[The, new, rights, are, nice, enough]</td>\n",
       "      <td>( ( The ( new rights ) ) ( are ( nice enough )...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (JJ new) (NNS rights)) (...</td>\n",
       "      <td>[Everyone, really, likes, the, newest, benefits]</td>\n",
       "      <td>( Everyone ( really ( likes ( the ( newest ben...</td>\n",
       "      <td>(ROOT (S (NP (NN Everyone)) (VP (ADVP (RB real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>government</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91383c</td>\n",
       "      <td>91383</td>\n",
       "      <td>[This, site, includes, a, list, of, all, award...</td>\n",
       "      <td>( ( This site ) ( ( includes ( ( ( ( a list ) ...</td>\n",
       "      <td>(ROOT (S (NP (DT This) (NN site)) (VP (VBZ inc...</td>\n",
       "      <td>[The, Government, Executive, articles, housed,...</td>\n",
       "      <td>( ( ( The ( Government ( Executive articles ) ...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT The) (NNP Government) (NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
       "      <td>telephone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>755e</td>\n",
       "      <td>755</td>\n",
       "      <td>[uh, i, do, n't, know, i, i, have, mixed, emot...</td>\n",
       "      <td>( ( ( ( uh ( i ( ( do n't ) ( know ( ( i i ) (...</td>\n",
       "      <td>(ROOT (SINV (S (S (INTJ (UH uh)) (NP (FW i)) (...</td>\n",
       "      <td>[I, like, him, for, the, most, part, ,, but, w...</td>\n",
       "      <td>( I ( ( ( ( ( ( like him ) ( for ( the ( most ...</td>\n",
       "      <td>(ROOT (S (NP (PRP I)) (VP (VP (VBP like) (NP (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>telephone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78013c</td>\n",
       "      <td>78013</td>\n",
       "      <td>[yeah, i, i, think, my, favorite, restaurant, ...</td>\n",
       "      <td>( yeah ( ( i i ) ( think ( ( my ( favorite res...</td>\n",
       "      <td>(ROOT (S (VP (VB yeah) (NP (NP (FW i) (FW i)) ...</td>\n",
       "      <td>[My, favorite, restaurants, are, always, at, l...</td>\n",
       "      <td>( ( My ( favorite restaurants ) ) ( ( ( ( are ...</td>\n",
       "      <td>(ROOT (S (NP (PRP$ My) (JJ favorite) (NNS rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>telephone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96377c</td>\n",
       "      <td>96377</td>\n",
       "      <td>[i, do, n't, know, um, do, you, do, a, lot, of...</td>\n",
       "      <td>( i ( ( do n't ) ( know ( um ( do ( you ( do (...</td>\n",
       "      <td>(ROOT (S (NP (FW i)) (VP (VBP do) (RB n't) (VP...</td>\n",
       "      <td>[I, know, exactly, .]</td>\n",
       "      <td>( I ( ( know exactly ) . ) )</td>\n",
       "      <td>(ROOT (S (NP (PRP I)) (VP (VBP know) (ADVP (RB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[neutral, neutral, entailment, neutral, entail...</td>\n",
       "      <td>government</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11879n</td>\n",
       "      <td>11879</td>\n",
       "      <td>[Since, 1998, ,, LSC, has, initiated, and, ove...</td>\n",
       "      <td>( ( Since 1998 ) ( , ( LSC ( ( has ( ( ( ( ( (...</td>\n",
       "      <td>(ROOT (S (PP (IN Since) (NP (CD 1998))) (, ,) ...</td>\n",
       "      <td>[LSC, has, been, focusing, on, improving, it, ...</td>\n",
       "      <td>( LSC ( ( has ( been ( focusing ( on ( ( impro...</td>\n",
       "      <td>(ROOT (S (NP (NNP LSC)) (VP (VBZ has) (VP (VBN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>slate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40715c</td>\n",
       "      <td>40715</td>\n",
       "      <td>[Eighty, percent, of, pagers, in, the, United,...</td>\n",
       "      <td>( ( ( Eighty percent ) ( of ( pagers ( in ( th...</td>\n",
       "      <td>(ROOT (S (NP (NP (JJ Eighty) (NN percent)) (PP...</td>\n",
       "      <td>[Pagers, in, the, United, States, were, unaffe...</td>\n",
       "      <td>( ( Pagers ( in ( the ( United States ) ) ) ) ...</td>\n",
       "      <td>(ROOT (S (NP (NP (NNS Pagers)) (PP (IN in) (NP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
       "      <td>government</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4294e</td>\n",
       "      <td>4294</td>\n",
       "      <td>[Finally, ,, the, FDA, will, conduct, workshop...</td>\n",
       "      <td>( Finally ( , ( ( the FDA ) ( ( will ( ( ( ( (...</td>\n",
       "      <td>(ROOT (S (ADVP (RB Finally)) (, ,) (NP (DT the...</td>\n",
       "      <td>[The, FDA, is, set, to, conduct, workshops, .]</td>\n",
       "      <td>( ( The FDA ) ( ( is ( set ( to ( conduct work...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NNP FDA)) (VP (VBZ is) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
       "      <td>travel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30880e</td>\n",
       "      <td>30880</td>\n",
       "      <td>[Cirque, du, Soleil, 's, The, latest, from, th...</td>\n",
       "      <td>( ( ( Cirque ( du Soleil ) ) ( 's ( ( The late...</td>\n",
       "      <td>(ROOT (S (S (NP (NNP Cirque) (NNP du) (NNP Sol...</td>\n",
       "      <td>[Cirque, du, Soleil, is, an, international, tr...</td>\n",
       "      <td>( ( Cirque ( du Soleil ) ) ( ( is ( an ( inter...</td>\n",
       "      <td>(ROOT (S (NP (NNP Cirque) (NNP du) (NNP Soleil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>telephone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76653c</td>\n",
       "      <td>76653</td>\n",
       "      <td>[i, 'll, listen, and, agree, with, what, i, th...</td>\n",
       "      <td>( i ( 'll ( ( listen and ) ( agree ( with ( wh...</td>\n",
       "      <td>(ROOT (S (NP (FW i)) (VP (MD 'll) (VP (VP (VB ...</td>\n",
       "      <td>[I, wont, even, bother, listening, .]</td>\n",
       "      <td>( I ( ( ( wont even ) ( bother listening ) ) ....</td>\n",
       "      <td>(ROOT (S (NP (PRP I)) (VP (VBP wont) (RB even)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       annotator_labels       genre  \\\n",
       "0      [neutral, entailment, neutral, neutral, neutral]       slate   \n",
       "1     [contradiction, contradiction, contradiction, ...  government   \n",
       "2     [entailment, entailment, entailment, entailmen...   telephone   \n",
       "3     [contradiction, contradiction, contradiction, ...   telephone   \n",
       "4     [contradiction, contradiction, contradiction, ...   telephone   \n",
       "...                                                 ...         ...   \n",
       "9995  [neutral, neutral, entailment, neutral, entail...  government   \n",
       "9996  [contradiction, contradiction, contradiction, ...       slate   \n",
       "9997  [entailment, entailment, entailment, entailmen...  government   \n",
       "9998  [entailment, entailment, entailment, entailmen...      travel   \n",
       "9999  [contradiction, contradiction, contradiction, ...   telephone   \n",
       "\n",
       "      gold_label  pairID  promptID  \\\n",
       "0            2.0  63735n     63735   \n",
       "1            0.0  91383c     91383   \n",
       "2            1.0    755e       755   \n",
       "3            0.0  78013c     78013   \n",
       "4            0.0  96377c     96377   \n",
       "...          ...     ...       ...   \n",
       "9995         2.0  11879n     11879   \n",
       "9996         0.0  40715c     40715   \n",
       "9997         1.0   4294e      4294   \n",
       "9998         1.0  30880e     30880   \n",
       "9999         0.0  76653c     76653   \n",
       "\n",
       "                                              sentence1  \\\n",
       "0                 [The, new, rights, are, nice, enough]   \n",
       "1     [This, site, includes, a, list, of, all, award...   \n",
       "2     [uh, i, do, n't, know, i, i, have, mixed, emot...   \n",
       "3     [yeah, i, i, think, my, favorite, restaurant, ...   \n",
       "4     [i, do, n't, know, um, do, you, do, a, lot, of...   \n",
       "...                                                 ...   \n",
       "9995  [Since, 1998, ,, LSC, has, initiated, and, ove...   \n",
       "9996  [Eighty, percent, of, pagers, in, the, United,...   \n",
       "9997  [Finally, ,, the, FDA, will, conduct, workshop...   \n",
       "9998  [Cirque, du, Soleil, 's, The, latest, from, th...   \n",
       "9999  [i, 'll, listen, and, agree, with, what, i, th...   \n",
       "\n",
       "                                 sentence1_binary_parse  \\\n",
       "0     ( ( The ( new rights ) ) ( are ( nice enough )...   \n",
       "1     ( ( This site ) ( ( includes ( ( ( ( a list ) ...   \n",
       "2     ( ( ( ( uh ( i ( ( do n't ) ( know ( ( i i ) (...   \n",
       "3     ( yeah ( ( i i ) ( think ( ( my ( favorite res...   \n",
       "4     ( i ( ( do n't ) ( know ( um ( do ( you ( do (...   \n",
       "...                                                 ...   \n",
       "9995  ( ( Since 1998 ) ( , ( LSC ( ( has ( ( ( ( ( (...   \n",
       "9996  ( ( ( Eighty percent ) ( of ( pagers ( in ( th...   \n",
       "9997  ( Finally ( , ( ( the FDA ) ( ( will ( ( ( ( (...   \n",
       "9998  ( ( ( Cirque ( du Soleil ) ) ( 's ( ( The late...   \n",
       "9999  ( i ( 'll ( ( listen and ) ( agree ( with ( wh...   \n",
       "\n",
       "                                        sentence1_parse  \\\n",
       "0     (ROOT (S (NP (DT The) (JJ new) (NNS rights)) (...   \n",
       "1     (ROOT (S (NP (DT This) (NN site)) (VP (VBZ inc...   \n",
       "2     (ROOT (SINV (S (S (INTJ (UH uh)) (NP (FW i)) (...   \n",
       "3     (ROOT (S (VP (VB yeah) (NP (NP (FW i) (FW i)) ...   \n",
       "4     (ROOT (S (NP (FW i)) (VP (VBP do) (RB n't) (VP...   \n",
       "...                                                 ...   \n",
       "9995  (ROOT (S (PP (IN Since) (NP (CD 1998))) (, ,) ...   \n",
       "9996  (ROOT (S (NP (NP (JJ Eighty) (NN percent)) (PP...   \n",
       "9997  (ROOT (S (ADVP (RB Finally)) (, ,) (NP (DT the...   \n",
       "9998  (ROOT (S (S (NP (NNP Cirque) (NNP du) (NNP Sol...   \n",
       "9999  (ROOT (S (NP (FW i)) (VP (MD 'll) (VP (VP (VB ...   \n",
       "\n",
       "                                              sentence2  \\\n",
       "0      [Everyone, really, likes, the, newest, benefits]   \n",
       "1     [The, Government, Executive, articles, housed,...   \n",
       "2     [I, like, him, for, the, most, part, ,, but, w...   \n",
       "3     [My, favorite, restaurants, are, always, at, l...   \n",
       "4                                 [I, know, exactly, .]   \n",
       "...                                                 ...   \n",
       "9995  [LSC, has, been, focusing, on, improving, it, ...   \n",
       "9996  [Pagers, in, the, United, States, were, unaffe...   \n",
       "9997     [The, FDA, is, set, to, conduct, workshops, .]   \n",
       "9998  [Cirque, du, Soleil, is, an, international, tr...   \n",
       "9999              [I, wont, even, bother, listening, .]   \n",
       "\n",
       "                                 sentence2_binary_parse  \\\n",
       "0     ( Everyone ( really ( likes ( the ( newest ben...   \n",
       "1     ( ( ( The ( Government ( Executive articles ) ...   \n",
       "2     ( I ( ( ( ( ( ( like him ) ( for ( the ( most ...   \n",
       "3     ( ( My ( favorite restaurants ) ) ( ( ( ( are ...   \n",
       "4                          ( I ( ( know exactly ) . ) )   \n",
       "...                                                 ...   \n",
       "9995  ( LSC ( ( has ( been ( focusing ( on ( ( impro...   \n",
       "9996  ( ( Pagers ( in ( the ( United States ) ) ) ) ...   \n",
       "9997  ( ( The FDA ) ( ( is ( set ( to ( conduct work...   \n",
       "9998  ( ( Cirque ( du Soleil ) ) ( ( is ( an ( inter...   \n",
       "9999  ( I ( ( ( wont even ) ( bother listening ) ) ....   \n",
       "\n",
       "                                        sentence2_parse  \n",
       "0     (ROOT (S (NP (NN Everyone)) (VP (ADVP (RB real...  \n",
       "1     (ROOT (S (NP (NP (DT The) (NNP Government) (NN...  \n",
       "2     (ROOT (S (NP (PRP I)) (VP (VP (VBP like) (NP (...  \n",
       "3     (ROOT (S (NP (PRP$ My) (JJ favorite) (NNS rest...  \n",
       "4     (ROOT (S (NP (PRP I)) (VP (VBP know) (ADVP (RB...  \n",
       "...                                                 ...  \n",
       "9995  (ROOT (S (NP (NNP LSC)) (VP (VBZ has) (VP (VBN...  \n",
       "9996  (ROOT (S (NP (NP (NNS Pagers)) (PP (IN in) (NP...  \n",
       "9997  (ROOT (S (NP (DT The) (NNP FDA)) (VP (VBZ is) ...  \n",
       "9998  (ROOT (S (NP (NNP Cirque) (NNP du) (NNP Soleil...  \n",
       "9999  (ROOT (S (NP (PRP I)) (VP (VBP wont) (RB even)...  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "word-vec: 1999996it [00:09, 204524.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# feature preprocessing\n",
    "voc = set()\n",
    "for index, row in dataset['train'].iterrows():\n",
    "    voc.update(row['sentence1'])\n",
    "    voc.update(row['sentence2'])\n",
    "words, vecs = load_word_vectors(\"crawl-300d-2M\", voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "w2v = {w: v/np.linalg.norm(v) for w, v in zip(words, vecs)}\n",
    "with open(\"w2v_mnli_cache\", \"wb\") as f:\n",
    "    pickle.dump(w2v, f)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ffacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_subseq(needle, haystack):\n",
    "  l = len(needle)\n",
    "  if l > len(haystack):\n",
    "    return False\n",
    "  else:\n",
    "    return any(haystack[i:i+l] == needle for i in range(len(haystack)-l + 1))\n",
    "\n",
    "dataset_to_features = {}\n",
    "for name in dataset.keys():\n",
    "    features = []\n",
    "    for index, row in dataset[name].iterrows():\n",
    "        h = [x.lower() for x in row.sentence1]\n",
    "        p = [x.lower() for x in row.sentence2]\n",
    "        p_words = set(p)\n",
    "        n_words_in_p = sum(x in p_words for x in h)\n",
    "        fe = {\n",
    "        \"h-is-subseq\": is_subseq(h, p),\n",
    "        \"all-in-p\": n_words_in_p == len(h),\n",
    "        \"percent-in-p\": n_words_in_p / len(h),\n",
    "        \"log-len-diff\": np.log(max(len(p) - len(h), 1)),\n",
    "        \"label\": row.gold_label\n",
    "        }    \n",
    "        h_vecs = [w2v[w] for w in row.sentence1 if w in w2v]\n",
    "        p_vecs = [w2v[w] for w in row.sentence2 if w in w2v]\n",
    "        if len(h_vecs) > 0 and len(p_vecs) > 0:\n",
    "          h_vecs = np.stack(h_vecs, 0)\n",
    "          p_vecs = np.stack(p_vecs, 0)\n",
    "          # [h_size, p_size]\n",
    "          similarities = np.matmul(h_vecs, p_vecs.T)\n",
    "          # [h_size]\n",
    "          similarities = np.max(similarities, 1)\n",
    "          similarities.sort()\n",
    "          fe[\"average-sim\"] = similarities.sum() / len(h)\n",
    "          fe[\"min-similarity\"] = similarities[0]\n",
    "          if len(similarities) > 1:\n",
    "            fe[\"min2-similarity\"] = similarities[1]\n",
    "\n",
    "        features.append(fe)\n",
    "    dataset_to_features[name] = pd.DataFrame(features)\n",
    "    dataset_to_features[name].fillna(0.0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100, class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100, class_weight=&#x27;balanced&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100, class_weight='balanced', solver='liblinear')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "train_df = dataset_to_features[\"train\"]\n",
    "feature_cols = [x for x in train_df.columns if x != \"label\"]\n",
    "\n",
    "# class_weight='balanced' will weight the entailemnt/non-entailment examples equally\n",
    "# C=100 means no regularization\n",
    "lr = LogisticRegression(multi_class=\"auto\", solver=\"liblinear\",\n",
    "                    class_weight='balanced', C=100)\n",
    "lr.fit(train_df[feature_cols].values, train_df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38118f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.4387 (size=392702)\n",
      "validation accuracy: 0.4394 (size=10000)\n",
      "test accuracy: 0.4528 (size=10000)\n"
     ]
    }
   ],
   "source": [
    "for name in dataset_to_features.keys():\n",
    "  examples = dataset_to_features[name]\n",
    "  pred = lr.predict_proba(dataset_to_features[name][feature_cols].values).astype(np.float32)\n",
    "  y = dataset_to_features[name].label.values\n",
    "\n",
    "  acc = np.mean(y == np.argmax(pred, 1))\n",
    "  print(\"%s accuracy: %.4f (size=%d)\" % (name, acc, len(examples)))\n",
    "\n",
    "  dataset[name][\"bias_probs\"]= pred.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b841009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One: load data\n",
    "ori_dataset = {}\n",
    "ori_dataset['train'] = pd.read_json('../../data/nli/multinli_1.0_train.jsonl', lines=True)\n",
    "ori_dataset['validation'] = pd.read_json('../../data/nli/multinli_1.0_dev_matched.jsonl', lines=True)\n",
    "ori_dataset['test'] = pd.read_json('../../data/nli/multinli_1.0_dev_mismatched.jsonl', lines=True)\n",
    "for key in dataset.keys():\n",
    "    ori_dataset[key]['bias_probs'] = dataset[key][\"bias_probs\"]\n",
    "    temp_json = ori_dataset[key].to_json(orient='records', lines=True)\n",
    "    with open('mnli_clark.'+key+'.jsonl', 'w') as json_file:\n",
    "        json_file.write(temp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc541849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotator_labels          0\n",
       "genre                     0\n",
       "gold_label                0\n",
       "pairID                    0\n",
       "promptID                  0\n",
       "sentence1                 0\n",
       "sentence1_binary_parse    0\n",
       "sentence1_parse           0\n",
       "sentence2                 0\n",
       "sentence2_binary_parse    0\n",
       "sentence2_parse           0\n",
       "bias_probs                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_dataset['train'].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchseq",
   "language": "python",
   "name": "torchseq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
