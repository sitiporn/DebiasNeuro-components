Loading path for single at seed:409, layer: 11
Q: ../counterfactuals/poe2/seed_409/avg_Q_counterfactual_representation.pickle
K: ../counterfactuals/poe2/seed_409/avg_K_counterfactual_representation.pickle
V: ../counterfactuals/poe2/seed_409/avg_V_counterfactual_representation.pickle
AO: ../counterfactuals/poe2/seed_409/avg_AO_counterfactual_representation.pickle
I: ../counterfactuals/poe2/seed_409/avg_I_counterfactual_representation.pickle
O: ../counterfactuals/poe2/seed_409/avg_O_counterfactual_representation.pickle
NIE_paths: ['../NIE/poe2/seed_409/avg_embeddings_High-overlap_computed_all_layers_.pickle']
current poe2 : seed : 409
== statistic ==
{'High-overlap': 0.7777777777777778, 'Low-overlap': 0.0}
loading NIE : ../NIE/poe2/seed_409/avg_embeddings_High-overlap_computed_all_layers_.pickle
++++++++ Component-Neuron_id: 0.05 neurons :+++++++++
Done saving top neurons into pickle !
Loading from ../pickles/advantaged/poe2_clean_409_inferences.pickle done ! 
Loading model from ../models/poe2/seed_409/checkpoint-24500/pytorch_model.bin
Loading model from : ../models/poe2/seed_409/checkpoint-24500/pytorch_model.bin to optimize on PCGU
freeze whole tensor: bert.embeddings.word_embeddings.weight
freeze whole tensor: bert.embeddings.position_embeddings.weight
freeze whole tensor: bert.embeddings.token_type_embeddings.weight
freeze whole tensor: bert.embeddings.LayerNorm.weight
freeze whole tensor: bert.embeddings.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.0.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.0.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.0.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.0.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.1.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.1.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.1.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.1.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.2.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.2.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.2.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.2.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.3.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.3.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.3.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.3.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.4.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.4.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.4.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.4.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.5.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.5.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.5.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.5.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.6.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.6.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.6.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.6.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.7.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.7.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.7.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.7.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.8.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.8.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.8.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.8.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.9.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.9.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.9.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.9.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.10.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.10.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.10.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.10.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.11.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.11.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.11.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.11.output.LayerNorm.bias
freeze whole tensor: bert.pooler.dense.weight
freeze whole tensor: bert.pooler.dense.bias
freeze whole tensor: classifier.weight
freeze whole tensor: classifier.bias
# weight train parameters:  4147 
# weight freeze parameters: 78797 
# weight total oparameters: 82944 
# bias train parameters:  4147 
# bias freeze parameters: 78797 
# bias total oparameters: 82944 
count_param : 165888
# weight train parameters:  4147 
# weight freeze parameters: 78797 
# weight total oparameters: 82944 
# bias train parameters:  4147 
# bias freeze parameters: 78797 
# bias total oparameters: 82944 
summary after combine parameters
********** weight  ************
# Train : 4147
# Freeze : 78797
# Total  : 82944
********** bias  ************
# Train : 4147
# Freeze : 78797
# Total  : 82944
saving 0's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer0_collect_param=False_components.pickle
saving 1's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer1_collect_param=False_components.pickle
saving 2's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer2_collect_param=False_components.pickle
saving 3's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer3_collect_param=False_components.pickle
saving 4's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer4_collect_param=False_components.pickle
saving 5's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer5_collect_param=False_components.pickle
saving 6's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer6_collect_param=False_components.pickle
saving 7's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer7_collect_param=False_components.pickle
saving 8's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer8_collect_param=False_components.pickle
saving 9's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer9_collect_param=False_components.pickle
saving 10's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer10_collect_param=False_components.pickle
saving 11's components into ../pickles/restore_weight/poe2/masking-0.05/409_layer11_collect_param=False_components.pickle
checking:bert.encoder.layer.0.attention.self.query.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.0.attention.self.query.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.0.attention.self.key.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.0.attention.self.key.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.0.attention.self.value.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.0.attention.self.value.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.0.attention.output.dense.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.0.attention.output.dense.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.0.intermediate.dense.weight, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.0.intermediate.dense.bias, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.0.output.dense.weight, frozen: 764, train: 4, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.0.output.dense.bias, frozen: 764, train: 4, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.1.attention.self.query.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.1.attention.self.query.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.1.attention.self.key.weight, frozen: 760, train: 8, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.1.attention.self.key.bias, frozen: 760, train: 8, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.1.attention.self.value.weight, frozen: 762, train: 6, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.1.attention.self.value.bias, frozen: 762, train: 6, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.1.attention.output.dense.weight, frozen: 762, train: 6, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.1.attention.output.dense.bias, frozen: 762, train: 6, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.1.intermediate.dense.weight, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.1.intermediate.dense.bias, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.1.output.dense.weight, frozen: 757, train: 11, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.1.output.dense.bias, frozen: 757, train: 11, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.2.attention.self.query.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.2.attention.self.query.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.2.attention.self.key.weight, frozen: 763, train: 5, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.2.attention.self.key.bias, frozen: 763, train: 5, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.2.attention.self.value.weight, frozen: 765, train: 3, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.2.attention.self.value.bias, frozen: 765, train: 3, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.2.attention.output.dense.weight, frozen: 755, train: 13, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.2.attention.output.dense.bias, frozen: 755, train: 13, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.2.intermediate.dense.weight, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.2.intermediate.dense.bias, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.2.output.dense.weight, frozen: 745, train: 23, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.2.output.dense.bias, frozen: 745, train: 23, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.3.attention.self.query.weight, frozen: 765, train: 3, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.3.attention.self.query.bias, frozen: 765, train: 3, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.3.attention.self.key.weight, frozen: 757, train: 11, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.3.attention.self.key.bias, frozen: 757, train: 11, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.3.attention.self.value.weight, frozen: 764, train: 4, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.3.attention.self.value.bias, frozen: 764, train: 4, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.3.attention.output.dense.weight, frozen: 737, train: 31, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.3.attention.output.dense.bias, frozen: 737, train: 31, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.3.intermediate.dense.weight, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.3.intermediate.dense.bias, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.3.output.dense.weight, frozen: 724, train: 44, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.3.output.dense.bias, frozen: 724, train: 44, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.4.attention.self.query.weight, frozen: 762, train: 6, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.4.attention.self.query.bias, frozen: 762, train: 6, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.4.attention.self.key.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.4.attention.self.key.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.4.attention.self.value.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.4.attention.self.value.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.4.attention.output.dense.weight, frozen: 696, train: 72, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.4.attention.output.dense.bias, frozen: 696, train: 72, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.4.intermediate.dense.weight, frozen: 3066, train: 6, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.4.intermediate.dense.bias, frozen: 3066, train: 6, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.4.output.dense.weight, frozen: 676, train: 92, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.4.output.dense.bias, frozen: 676, train: 92, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.5.attention.self.query.weight, frozen: 750, train: 18, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.5.attention.self.query.bias, frozen: 750, train: 18, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.5.attention.self.key.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.5.attention.self.key.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.5.attention.self.value.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.5.attention.self.value.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.5.attention.output.dense.weight, frozen: 647, train: 121, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.5.attention.output.dense.bias, frozen: 647, train: 121, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.5.intermediate.dense.weight, frozen: 3058, train: 14, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.5.intermediate.dense.bias, frozen: 3058, train: 14, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.5.output.dense.weight, frozen: 646, train: 122, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.5.output.dense.bias, frozen: 646, train: 122, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.6.attention.self.query.weight, frozen: 745, train: 23, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.6.attention.self.query.bias, frozen: 745, train: 23, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.6.attention.self.key.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.6.attention.self.key.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.6.attention.self.value.weight, frozen: 765, train: 3, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.6.attention.self.value.bias, frozen: 765, train: 3, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.6.attention.output.dense.weight, frozen: 618, train: 150, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.6.attention.output.dense.bias, frozen: 618, train: 150, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.6.intermediate.dense.weight, frozen: 3051, train: 21, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.6.intermediate.dense.bias, frozen: 3051, train: 21, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.6.output.dense.weight, frozen: 634, train: 134, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.6.output.dense.bias, frozen: 634, train: 134, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.7.attention.self.query.weight, frozen: 747, train: 21, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.7.attention.self.query.bias, frozen: 747, train: 21, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.7.attention.self.key.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.7.attention.self.key.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.7.attention.self.value.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.7.attention.self.value.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.7.attention.output.dense.weight, frozen: 609, train: 159, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.7.attention.output.dense.bias, frozen: 609, train: 159, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.7.intermediate.dense.weight, frozen: 3054, train: 18, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.7.intermediate.dense.bias, frozen: 3054, train: 18, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.7.output.dense.weight, frozen: 594, train: 174, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.7.output.dense.bias, frozen: 594, train: 174, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.8.attention.self.query.weight, frozen: 743, train: 25, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.8.attention.self.query.bias, frozen: 743, train: 25, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.8.attention.self.key.weight, frozen: 765, train: 3, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.8.attention.self.key.bias, frozen: 765, train: 3, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.8.attention.self.value.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.8.attention.self.value.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.8.attention.output.dense.weight, frozen: 576, train: 192, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.8.attention.output.dense.bias, frozen: 576, train: 192, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.8.intermediate.dense.weight, frozen: 3029, train: 43, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.8.intermediate.dense.bias, frozen: 3029, train: 43, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.8.output.dense.weight, frozen: 576, train: 192, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.8.output.dense.bias, frozen: 576, train: 192, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.9.attention.self.query.weight, frozen: 723, train: 45, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.9.attention.self.query.bias, frozen: 723, train: 45, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.9.attention.self.key.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.9.attention.self.key.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.9.attention.self.value.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.9.attention.self.value.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.9.attention.output.dense.weight, frozen: 536, train: 232, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.9.attention.output.dense.bias, frozen: 536, train: 232, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.9.intermediate.dense.weight, frozen: 3027, train: 45, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.9.intermediate.dense.bias, frozen: 3027, train: 45, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.9.output.dense.weight, frozen: 552, train: 216, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.9.output.dense.bias, frozen: 552, train: 216, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.10.attention.self.query.weight, frozen: 666, train: 102, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.10.attention.self.query.bias, frozen: 666, train: 102, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.10.attention.self.key.weight, frozen: 762, train: 6, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.10.attention.self.key.bias, frozen: 762, train: 6, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.10.attention.self.value.weight, frozen: 765, train: 3, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.10.attention.self.value.bias, frozen: 765, train: 3, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.10.attention.output.dense.weight, frozen: 494, train: 274, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.10.attention.output.dense.bias, frozen: 494, train: 274, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.10.intermediate.dense.weight, frozen: 3017, train: 55, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.10.intermediate.dense.bias, frozen: 3017, train: 55, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.10.output.dense.weight, frozen: 497, train: 271, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.10.output.dense.bias, frozen: 497, train: 271, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.11.attention.self.query.weight, frozen: 633, train: 135, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.11.attention.self.query.bias, frozen: 633, train: 135, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.11.attention.self.key.weight, frozen: 761, train: 7, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.11.attention.self.key.bias, frozen: 761, train: 7, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.11.attention.self.value.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.11.attention.self.value.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.11.attention.output.dense.weight, frozen: 378, train: 390, Total : 768 : torch.Size([768, 768])
checking:bert.encoder.layer.11.attention.output.dense.bias, frozen: 378, train: 390, Total : 768 : torch.Size([768])
checking:bert.encoder.layer.11.intermediate.dense.weight, frozen: 2976, train: 96, Total : 3072 : torch.Size([3072, 768])
checking:bert.encoder.layer.11.intermediate.dense.bias, frozen: 2976, train: 96, Total : 3072 : torch.Size([3072])
checking:bert.encoder.layer.11.output.dense.weight, frozen: 303, train: 465, Total : 768 : torch.Size([768, 3072])
checking:bert.encoder.layer.11.output.dense.bias, frozen: 303, train: 465, Total : 768 : torch.Size([768])
********* DEBUG *******
bert.encoder.layer.0.attention.self.query.weight
bert.encoder.layer.0.attention.self.query.bias
bert.encoder.layer.0.attention.self.key.weight
bert.encoder.layer.0.attention.self.key.bias
bert.encoder.layer.0.attention.self.value.weight
bert.encoder.layer.0.attention.self.value.bias
bert.encoder.layer.0.attention.output.dense.weight
bert.encoder.layer.0.attention.output.dense.bias
bert.encoder.layer.0.intermediate.dense.weight
bert.encoder.layer.0.intermediate.dense.bias
bert.encoder.layer.0.output.dense.weight
bert.encoder.layer.0.output.dense.bias
bert.encoder.layer.1.attention.self.query.weight
bert.encoder.layer.1.attention.self.query.bias
bert.encoder.layer.1.attention.self.key.weight
bert.encoder.layer.1.attention.self.key.bias
bert.encoder.layer.1.attention.self.value.weight
bert.encoder.layer.1.attention.self.value.bias
bert.encoder.layer.1.attention.output.dense.weight
bert.encoder.layer.1.attention.output.dense.bias
bert.encoder.layer.1.intermediate.dense.weight
bert.encoder.layer.1.intermediate.dense.bias
bert.encoder.layer.1.output.dense.weight
bert.encoder.layer.1.output.dense.bias
bert.encoder.layer.2.attention.self.query.weight
bert.encoder.layer.2.attention.self.query.bias
bert.encoder.layer.2.attention.self.key.weight
bert.encoder.layer.2.attention.self.key.bias
bert.encoder.layer.2.attention.self.value.weight
bert.encoder.layer.2.attention.self.value.bias
bert.encoder.layer.2.attention.output.dense.weight
bert.encoder.layer.2.attention.output.dense.bias
bert.encoder.layer.2.intermediate.dense.weight
bert.encoder.layer.2.intermediate.dense.bias
bert.encoder.layer.2.output.dense.weight
bert.encoder.layer.2.output.dense.bias
bert.encoder.layer.3.attention.self.query.weight
bert.encoder.layer.3.attention.self.query.bias
bert.encoder.layer.3.attention.self.key.weight
bert.encoder.layer.3.attention.self.key.bias
bert.encoder.layer.3.attention.self.value.weight
bert.encoder.layer.3.attention.self.value.bias
bert.encoder.layer.3.attention.output.dense.weight
bert.encoder.layer.3.attention.output.dense.bias
bert.encoder.layer.3.intermediate.dense.weight
bert.encoder.layer.3.intermediate.dense.bias
bert.encoder.layer.3.output.dense.weight
bert.encoder.layer.3.output.dense.bias
bert.encoder.layer.4.attention.self.query.weight
bert.encoder.layer.4.attention.self.query.bias
bert.encoder.layer.4.attention.self.key.weight
bert.encoder.layer.4.attention.self.key.bias
bert.encoder.layer.4.attention.self.value.weight
bert.encoder.layer.4.attention.self.value.bias
bert.encoder.layer.4.attention.output.dense.weight
bert.encoder.layer.4.attention.output.dense.bias
bert.encoder.layer.4.intermediate.dense.weight
bert.encoder.layer.4.intermediate.dense.bias
bert.encoder.layer.4.output.dense.weight
bert.encoder.layer.4.output.dense.bias
bert.encoder.layer.5.attention.self.query.weight
bert.encoder.layer.5.attention.self.query.bias
bert.encoder.layer.5.attention.self.key.weight
bert.encoder.layer.5.attention.self.key.bias
bert.encoder.layer.5.attention.self.value.weight
bert.encoder.layer.5.attention.self.value.bias
bert.encoder.layer.5.attention.output.dense.weight
bert.encoder.layer.5.attention.output.dense.bias
bert.encoder.layer.5.intermediate.dense.weight
bert.encoder.layer.5.intermediate.dense.bias
bert.encoder.layer.5.output.dense.weight
bert.encoder.layer.5.output.dense.bias
bert.encoder.layer.6.attention.self.query.weight
bert.encoder.layer.6.attention.self.query.bias
bert.encoder.layer.6.attention.self.key.weight
bert.encoder.layer.6.attention.self.key.bias
bert.encoder.layer.6.attention.self.value.weight
bert.encoder.layer.6.attention.self.value.bias
bert.encoder.layer.6.attention.output.dense.weight
bert.encoder.layer.6.attention.output.dense.bias
bert.encoder.layer.6.intermediate.dense.weight
bert.encoder.layer.6.intermediate.dense.bias
bert.encoder.layer.6.output.dense.weight
bert.encoder.layer.6.output.dense.bias
bert.encoder.layer.7.attention.self.query.weight
bert.encoder.layer.7.attention.self.query.bias
bert.encoder.layer.7.attention.self.key.weight
bert.encoder.layer.7.attention.self.key.bias
bert.encoder.layer.7.attention.self.value.weight
bert.encoder.layer.7.attention.self.value.bias
bert.encoder.layer.7.attention.output.dense.weight
bert.encoder.layer.7.attention.output.dense.bias
bert.encoder.layer.7.intermediate.dense.weight
bert.encoder.layer.7.intermediate.dense.bias
bert.encoder.layer.7.output.dense.weight
bert.encoder.layer.7.output.dense.bias
bert.encoder.layer.8.attention.self.query.weight
bert.encoder.layer.8.attention.self.query.bias
bert.encoder.layer.8.attention.self.key.weight
bert.encoder.layer.8.attention.self.key.bias
bert.encoder.layer.8.attention.self.value.weight
bert.encoder.layer.8.attention.self.value.bias
bert.encoder.layer.8.attention.output.dense.weight
bert.encoder.layer.8.attention.output.dense.bias
bert.encoder.layer.8.intermediate.dense.weight
bert.encoder.layer.8.intermediate.dense.bias
bert.encoder.layer.8.output.dense.weight
bert.encoder.layer.8.output.dense.bias
bert.encoder.layer.9.attention.self.query.weight
bert.encoder.layer.9.attention.self.query.bias
bert.encoder.layer.9.attention.self.key.weight
bert.encoder.layer.9.attention.self.key.bias
bert.encoder.layer.9.attention.self.value.weight
bert.encoder.layer.9.attention.self.value.bias
bert.encoder.layer.9.attention.output.dense.weight
bert.encoder.layer.9.attention.output.dense.bias
bert.encoder.layer.9.intermediate.dense.weight
bert.encoder.layer.9.intermediate.dense.bias
bert.encoder.layer.9.output.dense.weight
bert.encoder.layer.9.output.dense.bias
bert.encoder.layer.10.attention.self.query.weight
bert.encoder.layer.10.attention.self.query.bias
bert.encoder.layer.10.attention.self.key.weight
bert.encoder.layer.10.attention.self.key.bias
bert.encoder.layer.10.attention.self.value.weight
bert.encoder.layer.10.attention.self.value.bias
bert.encoder.layer.10.attention.output.dense.weight
bert.encoder.layer.10.attention.output.dense.bias
bert.encoder.layer.10.intermediate.dense.weight
bert.encoder.layer.10.intermediate.dense.bias
bert.encoder.layer.10.output.dense.weight
bert.encoder.layer.10.output.dense.bias
bert.encoder.layer.11.attention.self.query.weight
bert.encoder.layer.11.attention.self.query.bias
bert.encoder.layer.11.attention.self.key.weight
bert.encoder.layer.11.attention.self.key.bias
bert.encoder.layer.11.attention.self.value.weight
bert.encoder.layer.11.attention.self.value.bias
bert.encoder.layer.11.attention.output.dense.weight
bert.encoder.layer.11.attention.output.dense.bias
bert.encoder.layer.11.intermediate.dense.weight
bert.encoder.layer.11.intermediate.dense.bias
bert.encoder.layer.11.output.dense.weight
bert.encoder.layer.11.output.dense.bias
********* END 144 *********
********* Freeze with required_grad *******
bert.embeddings.word_embeddings.weight
bert.embeddings.position_embeddings.weight
bert.embeddings.token_type_embeddings.weight
bert.embeddings.LayerNorm.weight
bert.embeddings.LayerNorm.bias
bert.encoder.layer.0.attention.output.LayerNorm.weight
bert.encoder.layer.0.attention.output.LayerNorm.bias
bert.encoder.layer.0.output.LayerNorm.weight
bert.encoder.layer.0.output.LayerNorm.bias
bert.encoder.layer.1.attention.output.LayerNorm.weight
bert.encoder.layer.1.attention.output.LayerNorm.bias
bert.encoder.layer.1.output.LayerNorm.weight
bert.encoder.layer.1.output.LayerNorm.bias
bert.encoder.layer.2.attention.output.LayerNorm.weight
bert.encoder.layer.2.attention.output.LayerNorm.bias
bert.encoder.layer.2.output.LayerNorm.weight
bert.encoder.layer.2.output.LayerNorm.bias
bert.encoder.layer.3.attention.output.LayerNorm.weight
bert.encoder.layer.3.attention.output.LayerNorm.bias
bert.encoder.layer.3.output.LayerNorm.weight
bert.encoder.layer.3.output.LayerNorm.bias
bert.encoder.layer.4.attention.output.LayerNorm.weight
bert.encoder.layer.4.attention.output.LayerNorm.bias
bert.encoder.layer.4.output.LayerNorm.weight
bert.encoder.layer.4.output.LayerNorm.bias
bert.encoder.layer.5.attention.output.LayerNorm.weight
bert.encoder.layer.5.attention.output.LayerNorm.bias
bert.encoder.layer.5.output.LayerNorm.weight
bert.encoder.layer.5.output.LayerNorm.bias
bert.encoder.layer.6.attention.output.LayerNorm.weight
bert.encoder.layer.6.attention.output.LayerNorm.bias
bert.encoder.layer.6.output.LayerNorm.weight
bert.encoder.layer.6.output.LayerNorm.bias
bert.encoder.layer.7.attention.output.LayerNorm.weight
bert.encoder.layer.7.attention.output.LayerNorm.bias
bert.encoder.layer.7.output.LayerNorm.weight
bert.encoder.layer.7.output.LayerNorm.bias
bert.encoder.layer.8.attention.output.LayerNorm.weight
bert.encoder.layer.8.attention.output.LayerNorm.bias
bert.encoder.layer.8.output.LayerNorm.weight
bert.encoder.layer.8.output.LayerNorm.bias
bert.encoder.layer.9.attention.output.LayerNorm.weight
bert.encoder.layer.9.attention.output.LayerNorm.bias
bert.encoder.layer.9.output.LayerNorm.weight
bert.encoder.layer.9.output.LayerNorm.bias
bert.encoder.layer.10.attention.output.LayerNorm.weight
bert.encoder.layer.10.attention.output.LayerNorm.bias
bert.encoder.layer.10.output.LayerNorm.weight
bert.encoder.layer.10.output.LayerNorm.bias
bert.encoder.layer.11.attention.output.LayerNorm.weight
bert.encoder.layer.11.attention.output.LayerNorm.bias
bert.encoder.layer.11.output.LayerNorm.weight
bert.encoder.layer.11.output.LayerNorm.bias
bert.pooler.dense.weight
bert.pooler.dense.bias
classifier.weight
classifier.bias
********* END 57 *********
Total = 144 + 57 = 201
> /ist-project/scads/sit/DebiasNeuro-components/trainer.py(730)main()
(Pdb) 