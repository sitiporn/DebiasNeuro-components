Loading path for single at seed:409, layer: 11
Q: ../counterfactuals/recent_baseline/seed_409/avg_Q_counterfactual_representation.pickle
K: ../counterfactuals/recent_baseline/seed_409/avg_K_counterfactual_representation.pickle
V: ../counterfactuals/recent_baseline/seed_409/avg_V_counterfactual_representation.pickle
AO: ../counterfactuals/recent_baseline/seed_409/avg_AO_counterfactual_representation.pickle
I: ../counterfactuals/recent_baseline/seed_409/avg_I_counterfactual_representation.pickle
O: ../counterfactuals/recent_baseline/seed_409/avg_O_counterfactual_representation.pickle
NIE_paths: ['../NIE/recent_baseline/seed_409/avg_embeddings_High-overlap_computed_all_layers_.pickle']
current recent_baseline : seed : 409
== statistic ==
{'High-overlap': 0.7777777777777778, 'Low-overlap': 0.0}
loading NIE : ../NIE/recent_baseline/seed_409/avg_embeddings_High-overlap_computed_all_layers_.pickle
++++++++ Component-Neuron_id: 0.05 neurons :+++++++++
Done saving top neurons into pickle !
Loading from ../pickles/advantaged/recent_baseline_clean_409_inferences.pickle done ! 
Loading model from ../models/recent_baseline/seed_409/checkpoint-36500/pytorch_model.bin
Loading model from : ../models/recent_baseline/seed_409/checkpoint-36500/pytorch_model.bin to optimize on PCGU
freeze whole tensor: bert.embeddings.word_embeddings.weight
freeze whole tensor: bert.embeddings.position_embeddings.weight
freeze whole tensor: bert.embeddings.token_type_embeddings.weight
freeze whole tensor: bert.embeddings.LayerNorm.weight
freeze whole tensor: bert.embeddings.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.0.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.0.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.0.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.0.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.1.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.1.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.1.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.1.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.2.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.2.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.2.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.2.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.3.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.3.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.3.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.3.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.4.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.4.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.4.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.4.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.5.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.5.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.5.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.5.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.6.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.6.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.6.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.6.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.7.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.7.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.7.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.7.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.8.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.8.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.8.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.8.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.9.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.9.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.9.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.9.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.10.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.10.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.10.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.10.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.11.attention.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.11.attention.output.LayerNorm.bias
freeze whole tensor: bert.encoder.layer.11.output.LayerNorm.weight
freeze whole tensor: bert.encoder.layer.11.output.LayerNorm.bias
freeze whole tensor: bert.pooler.dense.weight
freeze whole tensor: bert.pooler.dense.bias
freeze whole tensor: classifier.weight
freeze whole tensor: classifier.bias
# weight train parameters:  4147 
# weight freeze parameters: 78797 
# weight total oparameters: 82944 
# bias train parameters:  4147 
# bias freeze parameters: 78797 
# bias total oparameters: 82944 
count_param : 165888
# weight train parameters:  4147 
# weight freeze parameters: 78797 
# weight total oparameters: 82944 
# bias train parameters:  4147 
# bias freeze parameters: 78797 
# bias total oparameters: 82944 
summary after combine parameters
********** weight  ************
# Train : 4147
# Freeze : 78797
# Total  : 82944
********** bias  ************
# Train : 4147
# Freeze : 78797
# Total  : 82944
saving 0's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer0_collect_param=False_components.pickle
saving 1's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer1_collect_param=False_components.pickle
saving 2's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer2_collect_param=False_components.pickle
saving 3's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer3_collect_param=False_components.pickle
saving 4's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer4_collect_param=False_components.pickle
saving 5's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer5_collect_param=False_components.pickle
saving 6's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer6_collect_param=False_components.pickle
saving 7's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer7_collect_param=False_components.pickle
saving 8's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer8_collect_param=False_components.pickle
saving 9's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer9_collect_param=False_components.pickle
saving 10's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer10_collect_param=False_components.pickle
saving 11's components into ../pickles/restore_weight/recent_baseline/masking-0.05/409_layer11_collect_param=False_components.pickle
checking:bert.encoder.layer.0.attention.self.query.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.0.attention.self.query.weight
checking:bert.encoder.layer.0.attention.self.query.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.0.attention.self.query.bias
checking:bert.encoder.layer.0.attention.self.key.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.0.attention.self.key.weight
checking:bert.encoder.layer.0.attention.self.key.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.0.attention.self.key.bias
checking:bert.encoder.layer.0.attention.self.value.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.0.attention.self.value.weight
checking:bert.encoder.layer.0.attention.self.value.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.0.attention.self.value.bias
checking:bert.encoder.layer.0.attention.output.dense.weight, frozen: 763, train: 5, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.0.attention.output.dense.weight
checking:bert.encoder.layer.0.attention.output.dense.bias, frozen: 763, train: 5, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.0.attention.output.dense.bias
checking:bert.encoder.layer.0.intermediate.dense.weight, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.0.intermediate.dense.weight
checking:bert.encoder.layer.0.intermediate.dense.bias, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.0.intermediate.dense.bias
checking:bert.encoder.layer.0.output.dense.weight, frozen: 762, train: 6, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.0.output.dense.weight
checking:bert.encoder.layer.0.output.dense.bias, frozen: 762, train: 6, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.0.output.dense.bias
checking:bert.encoder.layer.1.attention.self.query.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.1.attention.self.query.weight
checking:bert.encoder.layer.1.attention.self.query.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.1.attention.self.query.bias
checking:bert.encoder.layer.1.attention.self.key.weight, frozen: 762, train: 6, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.1.attention.self.key.weight
checking:bert.encoder.layer.1.attention.self.key.bias, frozen: 762, train: 6, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.1.attention.self.key.bias
checking:bert.encoder.layer.1.attention.self.value.weight, frozen: 764, train: 4, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.1.attention.self.value.weight
checking:bert.encoder.layer.1.attention.self.value.bias, frozen: 764, train: 4, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.1.attention.self.value.bias
checking:bert.encoder.layer.1.attention.output.dense.weight, frozen: 750, train: 18, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.1.attention.output.dense.weight
checking:bert.encoder.layer.1.attention.output.dense.bias, frozen: 750, train: 18, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.1.attention.output.dense.bias
checking:bert.encoder.layer.1.intermediate.dense.weight, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.1.intermediate.dense.weight
checking:bert.encoder.layer.1.intermediate.dense.bias, frozen: 3071, train: 1, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.1.intermediate.dense.bias
checking:bert.encoder.layer.1.output.dense.weight, frozen: 750, train: 18, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.1.output.dense.weight
checking:bert.encoder.layer.1.output.dense.bias, frozen: 750, train: 18, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.1.output.dense.bias
checking:bert.encoder.layer.2.attention.self.query.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.2.attention.self.query.weight
checking:bert.encoder.layer.2.attention.self.query.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.2.attention.self.query.bias
checking:bert.encoder.layer.2.attention.self.key.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.2.attention.self.key.weight
checking:bert.encoder.layer.2.attention.self.key.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.2.attention.self.key.bias
checking:bert.encoder.layer.2.attention.self.value.weight, frozen: 765, train: 3, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.2.attention.self.value.weight
checking:bert.encoder.layer.2.attention.self.value.bias, frozen: 765, train: 3, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.2.attention.self.value.bias
checking:bert.encoder.layer.2.attention.output.dense.weight, frozen: 737, train: 31, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.2.attention.output.dense.weight
checking:bert.encoder.layer.2.attention.output.dense.bias, frozen: 737, train: 31, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.2.attention.output.dense.bias
checking:bert.encoder.layer.2.intermediate.dense.weight, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.2.intermediate.dense.weight
checking:bert.encoder.layer.2.intermediate.dense.bias, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.2.intermediate.dense.bias
checking:bert.encoder.layer.2.output.dense.weight, frozen: 724, train: 44, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.2.output.dense.weight
checking:bert.encoder.layer.2.output.dense.bias, frozen: 724, train: 44, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.2.output.dense.bias
checking:bert.encoder.layer.3.attention.self.query.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.3.attention.self.query.weight
checking:bert.encoder.layer.3.attention.self.query.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.3.attention.self.query.bias
checking:bert.encoder.layer.3.attention.self.key.weight, frozen: 744, train: 24, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.3.attention.self.key.weight
checking:bert.encoder.layer.3.attention.self.key.bias, frozen: 744, train: 24, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.3.attention.self.key.bias
checking:bert.encoder.layer.3.attention.self.value.weight, frozen: 763, train: 5, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.3.attention.self.value.weight
checking:bert.encoder.layer.3.attention.self.value.bias, frozen: 763, train: 5, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.3.attention.self.value.bias
checking:bert.encoder.layer.3.attention.output.dense.weight, frozen: 731, train: 37, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.3.attention.output.dense.weight
checking:bert.encoder.layer.3.attention.output.dense.bias, frozen: 731, train: 37, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.3.attention.output.dense.bias
checking:bert.encoder.layer.3.intermediate.dense.weight, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.3.intermediate.dense.weight
checking:bert.encoder.layer.3.intermediate.dense.bias, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.3.intermediate.dense.bias
checking:bert.encoder.layer.3.output.dense.weight, frozen: 707, train: 61, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.3.output.dense.weight
checking:bert.encoder.layer.3.output.dense.bias, frozen: 707, train: 61, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.3.output.dense.bias
checking:bert.encoder.layer.4.attention.self.query.weight, frozen: 747, train: 21, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.4.attention.self.query.weight
checking:bert.encoder.layer.4.attention.self.query.bias, frozen: 747, train: 21, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.4.attention.self.query.bias
checking:bert.encoder.layer.4.attention.self.key.weight, frozen: 762, train: 6, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.4.attention.self.key.weight
checking:bert.encoder.layer.4.attention.self.key.bias, frozen: 762, train: 6, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.4.attention.self.key.bias
checking:bert.encoder.layer.4.attention.self.value.weight, frozen: 765, train: 3, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.4.attention.self.value.weight
checking:bert.encoder.layer.4.attention.self.value.bias, frozen: 765, train: 3, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.4.attention.self.value.bias
checking:bert.encoder.layer.4.attention.output.dense.weight, frozen: 689, train: 79, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.4.attention.output.dense.weight
checking:bert.encoder.layer.4.attention.output.dense.bias, frozen: 689, train: 79, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.4.attention.output.dense.bias
checking:bert.encoder.layer.4.intermediate.dense.weight, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.4.intermediate.dense.weight
checking:bert.encoder.layer.4.intermediate.dense.bias, frozen: 3069, train: 3, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.4.intermediate.dense.bias
checking:bert.encoder.layer.4.output.dense.weight, frozen: 681, train: 87, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.4.output.dense.weight
checking:bert.encoder.layer.4.output.dense.bias, frozen: 681, train: 87, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.4.output.dense.bias
checking:bert.encoder.layer.5.attention.self.query.weight, frozen: 739, train: 29, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.5.attention.self.query.weight
checking:bert.encoder.layer.5.attention.self.query.bias, frozen: 739, train: 29, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.5.attention.self.query.bias
checking:bert.encoder.layer.5.attention.self.key.weight, frozen: 767, train: 1, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.5.attention.self.key.weight
checking:bert.encoder.layer.5.attention.self.key.bias, frozen: 767, train: 1, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.5.attention.self.key.bias
checking:bert.encoder.layer.5.attention.self.value.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.5.attention.self.value.weight
checking:bert.encoder.layer.5.attention.self.value.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.5.attention.self.value.bias
checking:bert.encoder.layer.5.attention.output.dense.weight, frozen: 655, train: 113, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.5.attention.output.dense.weight
checking:bert.encoder.layer.5.attention.output.dense.bias, frozen: 655, train: 113, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.5.attention.output.dense.bias
checking:bert.encoder.layer.5.intermediate.dense.weight, frozen: 3055, train: 17, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.5.intermediate.dense.weight
checking:bert.encoder.layer.5.intermediate.dense.bias, frozen: 3055, train: 17, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.5.intermediate.dense.bias
checking:bert.encoder.layer.5.output.dense.weight, frozen: 649, train: 119, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.5.output.dense.weight
checking:bert.encoder.layer.5.output.dense.bias, frozen: 649, train: 119, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.5.output.dense.bias
checking:bert.encoder.layer.6.attention.self.query.weight, frozen: 746, train: 22, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.6.attention.self.query.weight
checking:bert.encoder.layer.6.attention.self.query.bias, frozen: 746, train: 22, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.6.attention.self.query.bias
checking:bert.encoder.layer.6.attention.self.key.weight, frozen: 763, train: 5, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.6.attention.self.key.weight
checking:bert.encoder.layer.6.attention.self.key.bias, frozen: 763, train: 5, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.6.attention.self.key.bias
checking:bert.encoder.layer.6.attention.self.value.weight, frozen: 764, train: 4, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.6.attention.self.value.weight
checking:bert.encoder.layer.6.attention.self.value.bias, frozen: 764, train: 4, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.6.attention.self.value.bias
checking:bert.encoder.layer.6.attention.output.dense.weight, frozen: 628, train: 140, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.6.attention.output.dense.weight
checking:bert.encoder.layer.6.attention.output.dense.bias, frozen: 628, train: 140, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.6.attention.output.dense.bias
checking:bert.encoder.layer.6.intermediate.dense.weight, frozen: 3050, train: 22, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.6.intermediate.dense.weight
checking:bert.encoder.layer.6.intermediate.dense.bias, frozen: 3050, train: 22, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.6.intermediate.dense.bias
checking:bert.encoder.layer.6.output.dense.weight, frozen: 640, train: 128, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.6.output.dense.weight
checking:bert.encoder.layer.6.output.dense.bias, frozen: 640, train: 128, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.6.output.dense.bias
checking:bert.encoder.layer.7.attention.self.query.weight, frozen: 754, train: 14, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.7.attention.self.query.weight
checking:bert.encoder.layer.7.attention.self.query.bias, frozen: 754, train: 14, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.7.attention.self.query.bias
checking:bert.encoder.layer.7.attention.self.key.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.7.attention.self.key.weight
checking:bert.encoder.layer.7.attention.self.key.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.7.attention.self.key.bias
checking:bert.encoder.layer.7.attention.self.value.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.7.attention.self.value.weight
checking:bert.encoder.layer.7.attention.self.value.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.7.attention.self.value.bias
checking:bert.encoder.layer.7.attention.output.dense.weight, frozen: 624, train: 144, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.7.attention.output.dense.weight
checking:bert.encoder.layer.7.attention.output.dense.bias, frozen: 624, train: 144, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.7.attention.output.dense.bias
checking:bert.encoder.layer.7.intermediate.dense.weight, frozen: 3054, train: 18, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.7.intermediate.dense.weight
checking:bert.encoder.layer.7.intermediate.dense.bias, frozen: 3054, train: 18, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.7.intermediate.dense.bias
checking:bert.encoder.layer.7.output.dense.weight, frozen: 607, train: 161, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.7.output.dense.weight
checking:bert.encoder.layer.7.output.dense.bias, frozen: 607, train: 161, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.7.output.dense.bias
checking:bert.encoder.layer.8.attention.self.query.weight, frozen: 730, train: 38, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.8.attention.self.query.weight
checking:bert.encoder.layer.8.attention.self.query.bias, frozen: 730, train: 38, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.8.attention.self.query.bias
checking:bert.encoder.layer.8.attention.self.key.weight, frozen: 764, train: 4, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.8.attention.self.key.weight
checking:bert.encoder.layer.8.attention.self.key.bias, frozen: 764, train: 4, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.8.attention.self.key.bias
checking:bert.encoder.layer.8.attention.self.value.weight, frozen: 768, train: 0, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.8.attention.self.value.weight
checking:bert.encoder.layer.8.attention.self.value.bias, frozen: 768, train: 0, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.8.attention.self.value.bias
checking:bert.encoder.layer.8.attention.output.dense.weight, frozen: 599, train: 169, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.8.attention.output.dense.weight
checking:bert.encoder.layer.8.attention.output.dense.bias, frozen: 599, train: 169, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.8.attention.output.dense.bias
checking:bert.encoder.layer.8.intermediate.dense.weight, frozen: 3026, train: 46, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.8.intermediate.dense.weight
checking:bert.encoder.layer.8.intermediate.dense.bias, frozen: 3026, train: 46, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.8.intermediate.dense.bias
checking:bert.encoder.layer.8.output.dense.weight, frozen: 571, train: 197, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.8.output.dense.weight
checking:bert.encoder.layer.8.output.dense.bias, frozen: 571, train: 197, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.8.output.dense.bias
checking:bert.encoder.layer.9.attention.self.query.weight, frozen: 721, train: 47, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.9.attention.self.query.weight
checking:bert.encoder.layer.9.attention.self.query.bias, frozen: 721, train: 47, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.9.attention.self.query.bias
checking:bert.encoder.layer.9.attention.self.key.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.9.attention.self.key.weight
checking:bert.encoder.layer.9.attention.self.key.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.9.attention.self.key.bias
checking:bert.encoder.layer.9.attention.self.value.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.9.attention.self.value.weight
checking:bert.encoder.layer.9.attention.self.value.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.9.attention.self.value.bias
checking:bert.encoder.layer.9.attention.output.dense.weight, frozen: 541, train: 227, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.9.attention.output.dense.weight
checking:bert.encoder.layer.9.attention.output.dense.bias, frozen: 541, train: 227, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.9.attention.output.dense.bias
checking:bert.encoder.layer.9.intermediate.dense.weight, frozen: 3023, train: 49, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.9.intermediate.dense.weight
checking:bert.encoder.layer.9.intermediate.dense.bias, frozen: 3023, train: 49, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.9.intermediate.dense.bias
checking:bert.encoder.layer.9.output.dense.weight, frozen: 525, train: 243, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.9.output.dense.weight
checking:bert.encoder.layer.9.output.dense.bias, frozen: 525, train: 243, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.9.output.dense.bias
checking:bert.encoder.layer.10.attention.self.query.weight, frozen: 663, train: 105, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.10.attention.self.query.weight
checking:bert.encoder.layer.10.attention.self.query.bias, frozen: 663, train: 105, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.10.attention.self.query.bias
checking:bert.encoder.layer.10.attention.self.key.weight, frozen: 756, train: 12, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.10.attention.self.key.weight
checking:bert.encoder.layer.10.attention.self.key.bias, frozen: 756, train: 12, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.10.attention.self.key.bias
checking:bert.encoder.layer.10.attention.self.value.weight, frozen: 763, train: 5, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.10.attention.self.value.weight
checking:bert.encoder.layer.10.attention.self.value.bias, frozen: 763, train: 5, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.10.attention.self.value.bias
checking:bert.encoder.layer.10.attention.output.dense.weight, frozen: 523, train: 245, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.10.attention.output.dense.weight
checking:bert.encoder.layer.10.attention.output.dense.bias, frozen: 523, train: 245, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.10.attention.output.dense.bias
checking:bert.encoder.layer.10.intermediate.dense.weight, frozen: 3002, train: 70, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.10.intermediate.dense.weight
checking:bert.encoder.layer.10.intermediate.dense.bias, frozen: 3002, train: 70, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.10.intermediate.dense.bias
checking:bert.encoder.layer.10.output.dense.weight, frozen: 495, train: 273, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.10.output.dense.weight
checking:bert.encoder.layer.10.output.dense.bias, frozen: 495, train: 273, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.10.output.dense.bias
checking:bert.encoder.layer.11.attention.self.query.weight, frozen: 646, train: 122, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.11.attention.self.query.weight
checking:bert.encoder.layer.11.attention.self.query.bias, frozen: 646, train: 122, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.11.attention.self.query.bias
checking:bert.encoder.layer.11.attention.self.key.weight, frozen: 760, train: 8, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.11.attention.self.key.weight
checking:bert.encoder.layer.11.attention.self.key.bias, frozen: 760, train: 8, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.11.attention.self.key.bias
checking:bert.encoder.layer.11.attention.self.value.weight, frozen: 766, train: 2, Total : 768 : torch.Size([768, 768])
exlude_grad func : bert.encoder.layer.11.attention.self.value.weight
checking:bert.encoder.layer.11.attention.self.value.bias, frozen: 766, train: 2, Total : 768 : torch.Size([768])
exlude_grad func : bert.encoder.layer.11.attention.self.value.bias
checking:bert.encoder.layer.11.attention.output.dense.weight, frozen: 433, train: 335, Total : 768 : torch.Size([768, 768])
exlude_grad func dense : bert.encoder.layer.11.attention.output.dense.weight
checking:bert.encoder.layer.11.attention.output.dense.bias, frozen: 433, train: 335, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.11.attention.output.dense.bias
checking:bert.encoder.layer.11.intermediate.dense.weight, frozen: 2961, train: 111, Total : 3072 : torch.Size([3072, 768])
exlude_grad func dense : bert.encoder.layer.11.intermediate.dense.weight
checking:bert.encoder.layer.11.intermediate.dense.bias, frozen: 2961, train: 111, Total : 3072 : torch.Size([3072])
exlude_grad func dense : bert.encoder.layer.11.intermediate.dense.bias
checking:bert.encoder.layer.11.output.dense.weight, frozen: 347, train: 421, Total : 768 : torch.Size([768, 3072])
exlude_grad func dense : bert.encoder.layer.11.output.dense.weight
checking:bert.encoder.layer.11.output.dense.bias, frozen: 347, train: 421, Total : 768 : torch.Size([768])
exlude_grad func dense : bert.encoder.layer.11.output.dense.bias
========= train_data ===========
========= validation_data ===========
========= test_data ===========
Config of dataloader
Group by len : True
Dynamics padding : True, DataCollatorWithPadding(tokenizer=PreTrainedTokenizerFast(name_or_path='../bert-base-uncased-mnli/', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')
learning_rate : 2.166737198476513e-07
label smoother is None :
call back reverse gradient func: bert.encoder.layer.11.output.dense.bias, torch.Size([768]), torch.Size([421])
call back masking_grad func: bert.encoder.layer.11.output.dense.bias, torch.Size([768]), torch.Size([347])
call back reverse gradient func: bert.encoder.layer.11.output.dense.weight, torch.Size([768, 3072]), torch.Size([421, 3072])
call back masking_grad func: bert.encoder.layer.11.output.dense.weight, torch.Size([768, 3072]), torch.Size([347, 3072])
call back reverse gradient func: bert.encoder.layer.11.intermediate.dense.bias, torch.Size([3072]), torch.Size([111])
call back masking_grad func: bert.encoder.layer.11.intermediate.dense.bias, torch.Size([3072]), torch.Size([2961])
call back reverse gradient func: bert.encoder.layer.11.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([111, 768])
call back masking_grad func: bert.encoder.layer.11.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([2961, 768])
call back reverse gradient func: bert.encoder.layer.11.attention.output.dense.bias, torch.Size([768]), torch.Size([335])
call back masking_grad func: bert.encoder.layer.11.attention.output.dense.bias, torch.Size([768]), torch.Size([433])
call back reverse gradient func: bert.encoder.layer.11.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([335, 768])
call back masking_grad func: bert.encoder.layer.11.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([433, 768])
call back reverse gradient func: bert.encoder.layer.11.attention.self.value.bias, torch.Size([768]), torch.Size([2])
call back masking_grad func: bert.encoder.layer.11.attention.self.value.bias, torch.Size([768]), torch.Size([766])
call back reverse gradient func: bert.encoder.layer.11.attention.self.value.weight, torch.Size([768, 768]), torch.Size([2, 768])
call back masking_grad func: bert.encoder.layer.11.attention.self.value.weight, torch.Size([768, 768]), torch.Size([766, 768])
call back reverse gradient func: bert.encoder.layer.11.attention.self.key.bias, torch.Size([768]), torch.Size([8])
call back masking_grad func: bert.encoder.layer.11.attention.self.key.bias, torch.Size([768]), torch.Size([760])
call back reverse gradient func: bert.encoder.layer.11.attention.self.key.weight, torch.Size([768, 768]), torch.Size([8, 768])
call back masking_grad func: bert.encoder.layer.11.attention.self.key.weight, torch.Size([768, 768]), torch.Size([760, 768])
call back reverse gradient func: bert.encoder.layer.11.attention.self.query.bias, torch.Size([768]), torch.Size([122])
call back masking_grad func: bert.encoder.layer.11.attention.self.query.bias, torch.Size([768]), torch.Size([646])
call back reverse gradient func: bert.encoder.layer.11.attention.self.query.weight, torch.Size([768, 768]), torch.Size([122, 768])
call back masking_grad func: bert.encoder.layer.11.attention.self.query.weight, torch.Size([768, 768]), torch.Size([646, 768])
call back reverse gradient func: bert.encoder.layer.10.output.dense.bias, torch.Size([768]), torch.Size([273])
call back masking_grad func: bert.encoder.layer.10.output.dense.bias, torch.Size([768]), torch.Size([495])
call back reverse gradient func: bert.encoder.layer.10.output.dense.weight, torch.Size([768, 3072]), torch.Size([273, 3072])
call back masking_grad func: bert.encoder.layer.10.output.dense.weight, torch.Size([768, 3072]), torch.Size([495, 3072])
call back reverse gradient func: bert.encoder.layer.10.intermediate.dense.bias, torch.Size([3072]), torch.Size([70])
call back masking_grad func: bert.encoder.layer.10.intermediate.dense.bias, torch.Size([3072]), torch.Size([3002])
call back reverse gradient func: bert.encoder.layer.10.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([70, 768])
call back masking_grad func: bert.encoder.layer.10.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3002, 768])
call back reverse gradient func: bert.encoder.layer.10.attention.output.dense.bias, torch.Size([768]), torch.Size([245])
call back masking_grad func: bert.encoder.layer.10.attention.output.dense.bias, torch.Size([768]), torch.Size([523])
call back reverse gradient func: bert.encoder.layer.10.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([245, 768])
call back masking_grad func: bert.encoder.layer.10.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([523, 768])
call back reverse gradient func: bert.encoder.layer.10.attention.self.value.bias, torch.Size([768]), torch.Size([5])
call back masking_grad func: bert.encoder.layer.10.attention.self.value.bias, torch.Size([768]), torch.Size([763])
call back reverse gradient func: bert.encoder.layer.10.attention.self.value.weight, torch.Size([768, 768]), torch.Size([5, 768])
call back masking_grad func: bert.encoder.layer.10.attention.self.value.weight, torch.Size([768, 768]), torch.Size([763, 768])
call back reverse gradient func: bert.encoder.layer.10.attention.self.key.bias, torch.Size([768]), torch.Size([12])
call back masking_grad func: bert.encoder.layer.10.attention.self.key.bias, torch.Size([768]), torch.Size([756])
call back reverse gradient func: bert.encoder.layer.10.attention.self.key.weight, torch.Size([768, 768]), torch.Size([12, 768])
call back masking_grad func: bert.encoder.layer.10.attention.self.key.weight, torch.Size([768, 768]), torch.Size([756, 768])
call back reverse gradient func: bert.encoder.layer.10.attention.self.query.bias, torch.Size([768]), torch.Size([105])
call back masking_grad func: bert.encoder.layer.10.attention.self.query.bias, torch.Size([768]), torch.Size([663])
call back reverse gradient func: bert.encoder.layer.10.attention.self.query.weight, torch.Size([768, 768]), torch.Size([105, 768])
call back masking_grad func: bert.encoder.layer.10.attention.self.query.weight, torch.Size([768, 768]), torch.Size([663, 768])
call back reverse gradient func: bert.encoder.layer.9.output.dense.bias, torch.Size([768]), torch.Size([243])
call back masking_grad func: bert.encoder.layer.9.output.dense.bias, torch.Size([768]), torch.Size([525])
call back reverse gradient func: bert.encoder.layer.9.output.dense.weight, torch.Size([768, 3072]), torch.Size([243, 3072])
call back masking_grad func: bert.encoder.layer.9.output.dense.weight, torch.Size([768, 3072]), torch.Size([525, 3072])
call back reverse gradient func: bert.encoder.layer.9.intermediate.dense.bias, torch.Size([3072]), torch.Size([49])
call back masking_grad func: bert.encoder.layer.9.intermediate.dense.bias, torch.Size([3072]), torch.Size([3023])
call back reverse gradient func: bert.encoder.layer.9.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([49, 768])
call back masking_grad func: bert.encoder.layer.9.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3023, 768])
call back reverse gradient func: bert.encoder.layer.9.attention.output.dense.bias, torch.Size([768]), torch.Size([227])
call back masking_grad func: bert.encoder.layer.9.attention.output.dense.bias, torch.Size([768]), torch.Size([541])
call back reverse gradient func: bert.encoder.layer.9.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([227, 768])
call back masking_grad func: bert.encoder.layer.9.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([541, 768])
call back reverse gradient func: bert.encoder.layer.9.attention.self.value.bias, torch.Size([768]), torch.Size([2])
call back masking_grad func: bert.encoder.layer.9.attention.self.value.bias, torch.Size([768]), torch.Size([766])
call back reverse gradient func: bert.encoder.layer.9.attention.self.value.weight, torch.Size([768, 768]), torch.Size([2, 768])
call back masking_grad func: bert.encoder.layer.9.attention.self.value.weight, torch.Size([768, 768]), torch.Size([766, 768])
call back reverse gradient func: bert.encoder.layer.9.attention.self.key.bias, torch.Size([768]), torch.Size([2])
call back masking_grad func: bert.encoder.layer.9.attention.self.key.bias, torch.Size([768]), torch.Size([766])
call back reverse gradient func: bert.encoder.layer.9.attention.self.key.weight, torch.Size([768, 768]), torch.Size([2, 768])
call back masking_grad func: bert.encoder.layer.9.attention.self.key.weight, torch.Size([768, 768]), torch.Size([766, 768])
call back reverse gradient func: bert.encoder.layer.9.attention.self.query.bias, torch.Size([768]), torch.Size([47])
call back masking_grad func: bert.encoder.layer.9.attention.self.query.bias, torch.Size([768]), torch.Size([721])
call back reverse gradient func: bert.encoder.layer.9.attention.self.query.weight, torch.Size([768, 768]), torch.Size([47, 768])
call back masking_grad func: bert.encoder.layer.9.attention.self.query.weight, torch.Size([768, 768]), torch.Size([721, 768])
call back reverse gradient func: bert.encoder.layer.8.output.dense.bias, torch.Size([768]), torch.Size([197])
call back masking_grad func: bert.encoder.layer.8.output.dense.bias, torch.Size([768]), torch.Size([571])
call back reverse gradient func: bert.encoder.layer.8.output.dense.weight, torch.Size([768, 3072]), torch.Size([197, 3072])
call back masking_grad func: bert.encoder.layer.8.output.dense.weight, torch.Size([768, 3072]), torch.Size([571, 3072])
call back reverse gradient func: bert.encoder.layer.8.intermediate.dense.bias, torch.Size([3072]), torch.Size([46])
call back masking_grad func: bert.encoder.layer.8.intermediate.dense.bias, torch.Size([3072]), torch.Size([3026])
call back reverse gradient func: bert.encoder.layer.8.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([46, 768])
call back masking_grad func: bert.encoder.layer.8.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3026, 768])
call back reverse gradient func: bert.encoder.layer.8.attention.output.dense.bias, torch.Size([768]), torch.Size([169])
call back masking_grad func: bert.encoder.layer.8.attention.output.dense.bias, torch.Size([768]), torch.Size([599])
call back reverse gradient func: bert.encoder.layer.8.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([169, 768])
call back masking_grad func: bert.encoder.layer.8.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([599, 768])
call back masking_grad func: bert.encoder.layer.8.attention.self.value.bias, torch.Size([768]), torch.Size([768])
call back masking_grad func: bert.encoder.layer.8.attention.self.value.weight, torch.Size([768, 768]), torch.Size([768, 768])
call back reverse gradient func: bert.encoder.layer.8.attention.self.key.bias, torch.Size([768]), torch.Size([4])
call back masking_grad func: bert.encoder.layer.8.attention.self.key.bias, torch.Size([768]), torch.Size([764])
call back reverse gradient func: bert.encoder.layer.8.attention.self.key.weight, torch.Size([768, 768]), torch.Size([4, 768])
call back masking_grad func: bert.encoder.layer.8.attention.self.key.weight, torch.Size([768, 768]), torch.Size([764, 768])
call back reverse gradient func: bert.encoder.layer.8.attention.self.query.bias, torch.Size([768]), torch.Size([38])
call back masking_grad func: bert.encoder.layer.8.attention.self.query.bias, torch.Size([768]), torch.Size([730])
call back reverse gradient func: bert.encoder.layer.8.attention.self.query.weight, torch.Size([768, 768]), torch.Size([38, 768])
call back masking_grad func: bert.encoder.layer.8.attention.self.query.weight, torch.Size([768, 768]), torch.Size([730, 768])
call back reverse gradient func: bert.encoder.layer.7.output.dense.bias, torch.Size([768]), torch.Size([161])
call back masking_grad func: bert.encoder.layer.7.output.dense.bias, torch.Size([768]), torch.Size([607])
call back reverse gradient func: bert.encoder.layer.7.output.dense.weight, torch.Size([768, 3072]), torch.Size([161, 3072])
call back masking_grad func: bert.encoder.layer.7.output.dense.weight, torch.Size([768, 3072]), torch.Size([607, 3072])
call back reverse gradient func: bert.encoder.layer.7.intermediate.dense.bias, torch.Size([3072]), torch.Size([18])
call back masking_grad func: bert.encoder.layer.7.intermediate.dense.bias, torch.Size([3072]), torch.Size([3054])
call back reverse gradient func: bert.encoder.layer.7.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([18, 768])
call back masking_grad func: bert.encoder.layer.7.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3054, 768])
call back reverse gradient func: bert.encoder.layer.7.attention.output.dense.bias, torch.Size([768]), torch.Size([144])
call back masking_grad func: bert.encoder.layer.7.attention.output.dense.bias, torch.Size([768]), torch.Size([624])
call back reverse gradient func: bert.encoder.layer.7.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([144, 768])
call back masking_grad func: bert.encoder.layer.7.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([624, 768])
call back masking_grad func: bert.encoder.layer.7.attention.self.value.bias, torch.Size([768]), torch.Size([768])
call back masking_grad func: bert.encoder.layer.7.attention.self.value.weight, torch.Size([768, 768]), torch.Size([768, 768])
call back masking_grad func: bert.encoder.layer.7.attention.self.key.bias, torch.Size([768]), torch.Size([768])
call back masking_grad func: bert.encoder.layer.7.attention.self.key.weight, torch.Size([768, 768]), torch.Size([768, 768])
call back reverse gradient func: bert.encoder.layer.7.attention.self.query.bias, torch.Size([768]), torch.Size([14])
call back masking_grad func: bert.encoder.layer.7.attention.self.query.bias, torch.Size([768]), torch.Size([754])
call back reverse gradient func: bert.encoder.layer.7.attention.self.query.weight, torch.Size([768, 768]), torch.Size([14, 768])
call back masking_grad func: bert.encoder.layer.7.attention.self.query.weight, torch.Size([768, 768]), torch.Size([754, 768])
call back reverse gradient func: bert.encoder.layer.6.output.dense.bias, torch.Size([768]), torch.Size([128])
call back masking_grad func: bert.encoder.layer.6.output.dense.bias, torch.Size([768]), torch.Size([640])
call back reverse gradient func: bert.encoder.layer.6.output.dense.weight, torch.Size([768, 3072]), torch.Size([128, 3072])
call back masking_grad func: bert.encoder.layer.6.output.dense.weight, torch.Size([768, 3072]), torch.Size([640, 3072])
call back reverse gradient func: bert.encoder.layer.6.intermediate.dense.bias, torch.Size([3072]), torch.Size([22])
call back masking_grad func: bert.encoder.layer.6.intermediate.dense.bias, torch.Size([3072]), torch.Size([3050])
call back reverse gradient func: bert.encoder.layer.6.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([22, 768])
call back masking_grad func: bert.encoder.layer.6.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3050, 768])
call back reverse gradient func: bert.encoder.layer.6.attention.output.dense.bias, torch.Size([768]), torch.Size([140])
call back masking_grad func: bert.encoder.layer.6.attention.output.dense.bias, torch.Size([768]), torch.Size([628])
call back reverse gradient func: bert.encoder.layer.6.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([140, 768])
call back masking_grad func: bert.encoder.layer.6.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([628, 768])
call back reverse gradient func: bert.encoder.layer.6.attention.self.value.bias, torch.Size([768]), torch.Size([4])
call back masking_grad func: bert.encoder.layer.6.attention.self.value.bias, torch.Size([768]), torch.Size([764])
call back reverse gradient func: bert.encoder.layer.6.attention.self.value.weight, torch.Size([768, 768]), torch.Size([4, 768])
call back masking_grad func: bert.encoder.layer.6.attention.self.value.weight, torch.Size([768, 768]), torch.Size([764, 768])
call back reverse gradient func: bert.encoder.layer.6.attention.self.key.bias, torch.Size([768]), torch.Size([5])
call back masking_grad func: bert.encoder.layer.6.attention.self.key.bias, torch.Size([768]), torch.Size([763])
call back reverse gradient func: bert.encoder.layer.6.attention.self.key.weight, torch.Size([768, 768]), torch.Size([5, 768])
call back masking_grad func: bert.encoder.layer.6.attention.self.key.weight, torch.Size([768, 768]), torch.Size([763, 768])
call back reverse gradient func: bert.encoder.layer.6.attention.self.query.bias, torch.Size([768]), torch.Size([22])
call back masking_grad func: bert.encoder.layer.6.attention.self.query.bias, torch.Size([768]), torch.Size([746])
call back reverse gradient func: bert.encoder.layer.6.attention.self.query.weight, torch.Size([768, 768]), torch.Size([22, 768])
call back masking_grad func: bert.encoder.layer.6.attention.self.query.weight, torch.Size([768, 768]), torch.Size([746, 768])
call back reverse gradient func: bert.encoder.layer.5.output.dense.bias, torch.Size([768]), torch.Size([119])
call back masking_grad func: bert.encoder.layer.5.output.dense.bias, torch.Size([768]), torch.Size([649])
call back reverse gradient func: bert.encoder.layer.5.output.dense.weight, torch.Size([768, 3072]), torch.Size([119, 3072])
call back masking_grad func: bert.encoder.layer.5.output.dense.weight, torch.Size([768, 3072]), torch.Size([649, 3072])
call back reverse gradient func: bert.encoder.layer.5.intermediate.dense.bias, torch.Size([3072]), torch.Size([17])
call back masking_grad func: bert.encoder.layer.5.intermediate.dense.bias, torch.Size([3072]), torch.Size([3055])
call back reverse gradient func: bert.encoder.layer.5.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([17, 768])
call back masking_grad func: bert.encoder.layer.5.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3055, 768])
call back reverse gradient func: bert.encoder.layer.5.attention.output.dense.bias, torch.Size([768]), torch.Size([113])
call back masking_grad func: bert.encoder.layer.5.attention.output.dense.bias, torch.Size([768]), torch.Size([655])
call back reverse gradient func: bert.encoder.layer.5.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([113, 768])
call back masking_grad func: bert.encoder.layer.5.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([655, 768])
call back masking_grad func: bert.encoder.layer.5.attention.self.value.bias, torch.Size([768]), torch.Size([768])
call back masking_grad func: bert.encoder.layer.5.attention.self.value.weight, torch.Size([768, 768]), torch.Size([768, 768])
call back reverse gradient func: bert.encoder.layer.5.attention.self.key.bias, torch.Size([768]), torch.Size([1])
call back masking_grad func: bert.encoder.layer.5.attention.self.key.bias, torch.Size([768]), torch.Size([767])
call back reverse gradient func: bert.encoder.layer.5.attention.self.key.weight, torch.Size([768, 768]), torch.Size([1, 768])
call back masking_grad func: bert.encoder.layer.5.attention.self.key.weight, torch.Size([768, 768]), torch.Size([767, 768])
call back reverse gradient func: bert.encoder.layer.5.attention.self.query.bias, torch.Size([768]), torch.Size([29])
call back masking_grad func: bert.encoder.layer.5.attention.self.query.bias, torch.Size([768]), torch.Size([739])
call back reverse gradient func: bert.encoder.layer.5.attention.self.query.weight, torch.Size([768, 768]), torch.Size([29, 768])
call back masking_grad func: bert.encoder.layer.5.attention.self.query.weight, torch.Size([768, 768]), torch.Size([739, 768])
call back reverse gradient func: bert.encoder.layer.4.output.dense.bias, torch.Size([768]), torch.Size([87])
call back masking_grad func: bert.encoder.layer.4.output.dense.bias, torch.Size([768]), torch.Size([681])
call back reverse gradient func: bert.encoder.layer.4.output.dense.weight, torch.Size([768, 3072]), torch.Size([87, 3072])
call back masking_grad func: bert.encoder.layer.4.output.dense.weight, torch.Size([768, 3072]), torch.Size([681, 3072])
call back reverse gradient func: bert.encoder.layer.4.intermediate.dense.bias, torch.Size([3072]), torch.Size([3])
call back masking_grad func: bert.encoder.layer.4.intermediate.dense.bias, torch.Size([3072]), torch.Size([3069])
call back reverse gradient func: bert.encoder.layer.4.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3, 768])
call back masking_grad func: bert.encoder.layer.4.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3069, 768])
call back reverse gradient func: bert.encoder.layer.4.attention.output.dense.bias, torch.Size([768]), torch.Size([79])
call back masking_grad func: bert.encoder.layer.4.attention.output.dense.bias, torch.Size([768]), torch.Size([689])
call back reverse gradient func: bert.encoder.layer.4.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([79, 768])
call back masking_grad func: bert.encoder.layer.4.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([689, 768])
call back reverse gradient func: bert.encoder.layer.4.attention.self.value.bias, torch.Size([768]), torch.Size([3])
call back masking_grad func: bert.encoder.layer.4.attention.self.value.bias, torch.Size([768]), torch.Size([765])
call back reverse gradient func: bert.encoder.layer.4.attention.self.value.weight, torch.Size([768, 768]), torch.Size([3, 768])
call back masking_grad func: bert.encoder.layer.4.attention.self.value.weight, torch.Size([768, 768]), torch.Size([765, 768])
call back reverse gradient func: bert.encoder.layer.4.attention.self.key.bias, torch.Size([768]), torch.Size([6])
call back masking_grad func: bert.encoder.layer.4.attention.self.key.bias, torch.Size([768]), torch.Size([762])
call back reverse gradient func: bert.encoder.layer.4.attention.self.key.weight, torch.Size([768, 768]), torch.Size([6, 768])
call back masking_grad func: bert.encoder.layer.4.attention.self.key.weight, torch.Size([768, 768]), torch.Size([762, 768])
call back reverse gradient func: bert.encoder.layer.4.attention.self.query.bias, torch.Size([768]), torch.Size([21])
call back masking_grad func: bert.encoder.layer.4.attention.self.query.bias, torch.Size([768]), torch.Size([747])
call back reverse gradient func: bert.encoder.layer.4.attention.self.query.weight, torch.Size([768, 768]), torch.Size([21, 768])
call back masking_grad func: bert.encoder.layer.4.attention.self.query.weight, torch.Size([768, 768]), torch.Size([747, 768])
call back reverse gradient func: bert.encoder.layer.3.output.dense.bias, torch.Size([768]), torch.Size([61])
call back masking_grad func: bert.encoder.layer.3.output.dense.bias, torch.Size([768]), torch.Size([707])
call back reverse gradient func: bert.encoder.layer.3.output.dense.weight, torch.Size([768, 3072]), torch.Size([61, 3072])
call back masking_grad func: bert.encoder.layer.3.output.dense.weight, torch.Size([768, 3072]), torch.Size([707, 3072])
call back reverse gradient func: bert.encoder.layer.3.intermediate.dense.bias, torch.Size([3072]), torch.Size([3])
call back masking_grad func: bert.encoder.layer.3.intermediate.dense.bias, torch.Size([3072]), torch.Size([3069])
call back reverse gradient func: bert.encoder.layer.3.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3, 768])
call back masking_grad func: bert.encoder.layer.3.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3069, 768])
call back reverse gradient func: bert.encoder.layer.3.attention.output.dense.bias, torch.Size([768]), torch.Size([37])
call back masking_grad func: bert.encoder.layer.3.attention.output.dense.bias, torch.Size([768]), torch.Size([731])
call back reverse gradient func: bert.encoder.layer.3.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([37, 768])
call back masking_grad func: bert.encoder.layer.3.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([731, 768])
call back reverse gradient func: bert.encoder.layer.3.attention.self.value.bias, torch.Size([768]), torch.Size([5])
call back masking_grad func: bert.encoder.layer.3.attention.self.value.bias, torch.Size([768]), torch.Size([763])
call back reverse gradient func: bert.encoder.layer.3.attention.self.value.weight, torch.Size([768, 768]), torch.Size([5, 768])
call back masking_grad func: bert.encoder.layer.3.attention.self.value.weight, torch.Size([768, 768]), torch.Size([763, 768])
call back reverse gradient func: bert.encoder.layer.3.attention.self.key.bias, torch.Size([768]), torch.Size([24])
call back masking_grad func: bert.encoder.layer.3.attention.self.key.bias, torch.Size([768]), torch.Size([744])
call back reverse gradient func: bert.encoder.layer.3.attention.self.key.weight, torch.Size([768, 768]), torch.Size([24, 768])
call back masking_grad func: bert.encoder.layer.3.attention.self.key.weight, torch.Size([768, 768]), torch.Size([744, 768])
call back reverse gradient func: bert.encoder.layer.3.attention.self.query.bias, torch.Size([768]), torch.Size([2])
call back masking_grad func: bert.encoder.layer.3.attention.self.query.bias, torch.Size([768]), torch.Size([766])
call back reverse gradient func: bert.encoder.layer.3.attention.self.query.weight, torch.Size([768, 768]), torch.Size([2, 768])
call back masking_grad func: bert.encoder.layer.3.attention.self.query.weight, torch.Size([768, 768]), torch.Size([766, 768])
call back reverse gradient func: bert.encoder.layer.2.output.dense.bias, torch.Size([768]), torch.Size([44])
call back masking_grad func: bert.encoder.layer.2.output.dense.bias, torch.Size([768]), torch.Size([724])
call back reverse gradient func: bert.encoder.layer.2.output.dense.weight, torch.Size([768, 3072]), torch.Size([44, 3072])
call back masking_grad func: bert.encoder.layer.2.output.dense.weight, torch.Size([768, 3072]), torch.Size([724, 3072])
call back reverse gradient func: bert.encoder.layer.2.intermediate.dense.bias, torch.Size([3072]), torch.Size([3])
call back masking_grad func: bert.encoder.layer.2.intermediate.dense.bias, torch.Size([3072]), torch.Size([3069])
call back reverse gradient func: bert.encoder.layer.2.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3, 768])
call back masking_grad func: bert.encoder.layer.2.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3069, 768])
call back reverse gradient func: bert.encoder.layer.2.attention.output.dense.bias, torch.Size([768]), torch.Size([31])
call back masking_grad func: bert.encoder.layer.2.attention.output.dense.bias, torch.Size([768]), torch.Size([737])
call back reverse gradient func: bert.encoder.layer.2.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([31, 768])
call back masking_grad func: bert.encoder.layer.2.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([737, 768])
call back reverse gradient func: bert.encoder.layer.2.attention.self.value.bias, torch.Size([768]), torch.Size([3])
call back masking_grad func: bert.encoder.layer.2.attention.self.value.bias, torch.Size([768]), torch.Size([765])
call back reverse gradient func: bert.encoder.layer.2.attention.self.value.weight, torch.Size([768, 768]), torch.Size([3, 768])
call back masking_grad func: bert.encoder.layer.2.attention.self.value.weight, torch.Size([768, 768]), torch.Size([765, 768])
call back reverse gradient func: bert.encoder.layer.2.attention.self.key.bias, torch.Size([768]), torch.Size([2])
call back masking_grad func: bert.encoder.layer.2.attention.self.key.bias, torch.Size([768]), torch.Size([766])
call back reverse gradient func: bert.encoder.layer.2.attention.self.key.weight, torch.Size([768, 768]), torch.Size([2, 768])
call back masking_grad func: bert.encoder.layer.2.attention.self.key.weight, torch.Size([768, 768]), torch.Size([766, 768])
call back reverse gradient func: bert.encoder.layer.2.attention.self.query.bias, torch.Size([768]), torch.Size([1])
call back masking_grad func: bert.encoder.layer.2.attention.self.query.bias, torch.Size([768]), torch.Size([767])
call back reverse gradient func: bert.encoder.layer.2.attention.self.query.weight, torch.Size([768, 768]), torch.Size([1, 768])
call back masking_grad func: bert.encoder.layer.2.attention.self.query.weight, torch.Size([768, 768]), torch.Size([767, 768])
call back reverse gradient func: bert.encoder.layer.1.output.dense.bias, torch.Size([768]), torch.Size([18])
call back masking_grad func: bert.encoder.layer.1.output.dense.bias, torch.Size([768]), torch.Size([750])
call back reverse gradient func: bert.encoder.layer.1.output.dense.weight, torch.Size([768, 3072]), torch.Size([18, 3072])
call back masking_grad func: bert.encoder.layer.1.output.dense.weight, torch.Size([768, 3072]), torch.Size([750, 3072])
call back reverse gradient func: bert.encoder.layer.1.intermediate.dense.bias, torch.Size([3072]), torch.Size([1])
call back masking_grad func: bert.encoder.layer.1.intermediate.dense.bias, torch.Size([3072]), torch.Size([3071])
call back reverse gradient func: bert.encoder.layer.1.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([1, 768])
call back masking_grad func: bert.encoder.layer.1.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3071, 768])
call back reverse gradient func: bert.encoder.layer.1.attention.output.dense.bias, torch.Size([768]), torch.Size([18])
call back masking_grad func: bert.encoder.layer.1.attention.output.dense.bias, torch.Size([768]), torch.Size([750])
call back reverse gradient func: bert.encoder.layer.1.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([18, 768])
call back masking_grad func: bert.encoder.layer.1.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([750, 768])
call back reverse gradient func: bert.encoder.layer.1.attention.self.value.bias, torch.Size([768]), torch.Size([4])
call back masking_grad func: bert.encoder.layer.1.attention.self.value.bias, torch.Size([768]), torch.Size([764])
call back reverse gradient func: bert.encoder.layer.1.attention.self.value.weight, torch.Size([768, 768]), torch.Size([4, 768])
call back masking_grad func: bert.encoder.layer.1.attention.self.value.weight, torch.Size([768, 768]), torch.Size([764, 768])
call back reverse gradient func: bert.encoder.layer.1.attention.self.key.bias, torch.Size([768]), torch.Size([6])
call back masking_grad func: bert.encoder.layer.1.attention.self.key.bias, torch.Size([768]), torch.Size([762])
call back reverse gradient func: bert.encoder.layer.1.attention.self.key.weight, torch.Size([768, 768]), torch.Size([6, 768])
call back masking_grad func: bert.encoder.layer.1.attention.self.key.weight, torch.Size([768, 768]), torch.Size([762, 768])
call back reverse gradient func: bert.encoder.layer.1.attention.self.query.bias, torch.Size([768]), torch.Size([1])
call back masking_grad func: bert.encoder.layer.1.attention.self.query.bias, torch.Size([768]), torch.Size([767])
call back reverse gradient func: bert.encoder.layer.1.attention.self.query.weight, torch.Size([768, 768]), torch.Size([1, 768])
call back masking_grad func: bert.encoder.layer.1.attention.self.query.weight, torch.Size([768, 768]), torch.Size([767, 768])
call back reverse gradient func: bert.encoder.layer.0.output.dense.bias, torch.Size([768]), torch.Size([6])
call back masking_grad func: bert.encoder.layer.0.output.dense.bias, torch.Size([768]), torch.Size([762])
call back reverse gradient func: bert.encoder.layer.0.output.dense.weight, torch.Size([768, 3072]), torch.Size([6, 3072])
call back masking_grad func: bert.encoder.layer.0.output.dense.weight, torch.Size([768, 3072]), torch.Size([762, 3072])
call back reverse gradient func: bert.encoder.layer.0.intermediate.dense.bias, torch.Size([3072]), torch.Size([1])
call back masking_grad func: bert.encoder.layer.0.intermediate.dense.bias, torch.Size([3072]), torch.Size([3071])
call back reverse gradient func: bert.encoder.layer.0.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([1, 768])
call back masking_grad func: bert.encoder.layer.0.intermediate.dense.weight, torch.Size([3072, 768]), torch.Size([3071, 768])
call back reverse gradient func: bert.encoder.layer.0.attention.output.dense.bias, torch.Size([768]), torch.Size([5])
call back masking_grad func: bert.encoder.layer.0.attention.output.dense.bias, torch.Size([768]), torch.Size([763])
call back reverse gradient func: bert.encoder.layer.0.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([5, 768])
call back masking_grad func: bert.encoder.layer.0.attention.output.dense.weight, torch.Size([768, 768]), torch.Size([763, 768])
call back masking_grad func: bert.encoder.layer.0.attention.self.value.bias, torch.Size([768]), torch.Size([768])
call back masking_grad func: bert.encoder.layer.0.attention.self.value.weight, torch.Size([768, 768]), torch.Size([768, 768])
call back reverse gradient func: bert.encoder.layer.0.attention.self.key.bias, torch.Size([768]), torch.Size([1])
call back masking_grad func: bert.encoder.layer.0.attention.self.key.bias, torch.Size([768]), torch.Size([767])
call back reverse gradient func: bert.encoder.layer.0.attention.self.key.weight, torch.Size([768, 768]), torch.Size([1, 768])
call back masking_grad func: bert.encoder.layer.0.attention.self.key.weight, torch.Size([768, 768]), torch.Size([767, 768])
call back reverse gradient func: bert.encoder.layer.0.attention.self.query.bias, torch.Size([768]), torch.Size([1])
call back masking_grad func: bert.encoder.layer.0.attention.self.query.bias, torch.Size([768]), torch.Size([767])
call back reverse gradient func: bert.encoder.layer.0.attention.self.query.weight, torch.Size([768, 768]), torch.Size([1, 768])
call back masking_grad func: bert.encoder.layer.0.attention.self.query.weight, torch.Size([768, 768]), torch.Size([767, 768])
